{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with the Signal AI API using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: run `pip install -r requirements.txt` to install the dependencies for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backoff\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import math\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to the Signal AI API data science tutorial. \n",
    "In this notebook we will explore how to interact with the Signal AI API using Python.\n",
    "\n",
    "This Getting Started guide is designed to complement the full documentation for the API which can be found at:\n",
    "\n",
    "https://api.signal-ai.com/docs\n",
    "\n",
    "\n",
    "## What can I do with the Signal AI API?\n",
    "\n",
    "The Signal AI API provides a new and interesting way to search and explore news stories by examining which entities and topics appear in which stories, and when.\n",
    "\n",
    "### Entities\n",
    "A set of people, organisations, locations, substances, diseases and products identified by the Signal AI system. \n",
    "Mentions of entities are tracked along with their saliency (prominence) and sentiment (positive, neutral or negative).\n",
    "\n",
    "### Topics\n",
    "Over 300 topics (or themes), from Health to Blockchain, relevant to businesses.\n",
    "\n",
    "### Documents\n",
    "Documents are news stories with associated metadata such as publication date, language, media type, publication source and title. \n",
    "Each document is supplied with a list of entities and topics.\n",
    "The full text for each news story is not currently available through the API.\n",
    "\n",
    "### Queries\n",
    "\n",
    "The following are examples of questions one could answer using the Signal AI API:\n",
    "\n",
    "> How many documents mentioned a company in relation to the Environment this year?\n",
    "\n",
    "> Do mentions of a company have more positive or negative sentiment when a particular individual or location is also mentioned? How has this evolved over time? Does this depend on the publication source?\n",
    "\n",
    "> Which topics, locations, organisations are most frequently mentioned alongside a particular individual?\n",
    "\n",
    "> How many documents mention entity A but not entity B\n",
    "\n",
    "During this tutorial we'll gradually build up the knowledge to answer these questions.\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "Firstly we will explore some basic usage of the API such as authentication and the pagination system.\n",
    "Then we'll explore the different topics and entities available before building some search queries.\n",
    "\n",
    "We'll be using the popular requests library to communicate with the API and pandas to manipulate and visualise the data but prior experience with these libraries is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start lets make sure this machine can contact the Signal AI API using the requests library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://api.signal-ai.com\")\n",
    "if response.ok:\n",
    "    print('Successfully sent a request to the Signal AI API')\n",
    "else:\n",
    "    print('Error: Cannot communicate with the Signal AI API')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need a `client_id` and `client_secret` to gain access to the API.\n",
    "The code below will assume they have been set and the environment variables `SIGNAL_API_CLIENT_ID` and `SIGNAL_API_CLIENT_SECRET` respectively.\n",
    "\n",
    "Using your credentials you can request a temporary access token from the API using the url:\n",
    "\n",
    "`https://api.signal-ai.com/auth/token`\n",
    "\n",
    "Since we will be using this token a lot lets create a small class to authenticate against the Signal AI API using the requests library.\n",
    "\n",
    "We'll also add a method called `request` that can be used to send queries to the API with the new temporary access token. Keep in mind this token is only valid for 24 hours and you may need to call `authenticate` to request a new token from time to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate(client_id, client_secret, url = \"https://api.signal-ai.com\"):\n",
    "    \"\"\" obtain a temporary access token using user credentials \"\"\"\n",
    "    token_url = f'{url}/auth/token'\n",
    "    payload = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": client_id,\n",
    "        \"client_secret\": client_secret\n",
    "    }\n",
    "    response = requests.post(token_url, data=payload)\n",
    "    return response.json().get(\"access_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once authenticated the token will last for 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_ACCESS_TOKEN = authenticate(os.environ['SIGNAL_API_CLIENT_ID'], os.environ['SIGNAL_API_CLIENT_SECRET'])\n",
    "if TEMP_ACCESS_TOKEN:\n",
    "    print('Congratulations! You have an access token, it will last for 24 hours before you will need to reauthenticate by repeating this step')\n",
    "else:\n",
    "    print('Error: Perhaps the credentials are incorrect?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Simple Request\n",
    "\n",
    "Here's an example request showing how to use the access token.\n",
    "The results will always come back as JSON.\n",
    "We'll explore the specific endpoints and parameters in more detail later.\n",
    "Notice the `next-cursor` key in the results.\n",
    "By default ten results are returned in each response, to get the next 10 we need to paginate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    # call the entities endpoint\n",
    "    'https://api.signal-ai.com/entities',\n",
    "    params={\n",
    "        # Look for entities containing the token 'Environment'\n",
    "        'name':'Environment',\n",
    "        # Limit the search to organisations\n",
    "        'type':'organisation'\n",
    "    },\n",
    "    # include the access token in the header\n",
    "    headers={\n",
    "        \"Authorization\": f'Bearer {TEMP_ACCESS_TOKEN}',\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    ")\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rate Limiting and Retries\n",
    "\n",
    "Sometimes if the usage limits of the API are exceeded or if there is a short connection issue you may need to repeat a failed request.\n",
    "The backoff library is a really easy way to do this.\n",
    "It's a good idea to use backoff if you are making a lot or requests in a script or function, otherwise a single error might cause it to terminate.\n",
    "Let's use backoff and put together everything so far in a simple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom error for 429 HTTP errors. \n",
    "# We will raise it when the API returns this error meaning that we hit a rate limit \n",
    "class RateLimitError(Exception):\n",
    "    pass\n",
    "\n",
    "# retry requests with an exponentially increasing wait time upto 10 times\n",
    "@backoff.on_exception(\n",
    "    backoff.expo, \n",
    "    RateLimitError,\n",
    "    max_value=10)\n",
    "def request(method, endpoint, params=None, json=None):\n",
    "    \"\"\" Make get requests using a tempory access token \"\"\"\n",
    "    \n",
    "    response = requests.request(\n",
    "        method,\n",
    "        f'https://api.signal-ai.com/{endpoint}',\n",
    "        params=params,\n",
    "        json=json,\n",
    "        headers={\n",
    "            \"Authorization\": f'Bearer {TEMP_ACCESS_TOKEN}',\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    # cehck if we hit the rate limit\n",
    "    if response.status_code == 429: \n",
    "        raise RateLimitError\n",
    "    \n",
    "    # in all cases raise an exception if the status is not success\n",
    "    response.raise_for_status()\n",
    "    return response\n",
    "\n",
    "\n",
    "request('GET', 'entities', {'name': 'Environment'}).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pagination\n",
    "\n",
    "In the previous example the response contained a `next-cursor` key. \n",
    "By default, responses contain 10 items and the `next-cursor` allows us to get the next page of 10 items.\n",
    "If there is no `next-cursor` key then there are no more items remaining.\n",
    "To get the next page, use the token provided by `next-cursor` in your next request as the `from-cursor`\n",
    "\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pagination Example:\n",
    "\n",
    "page_0 = request('GET', 'entities', {'name': 'Environment'})\n",
    "\n",
    "page_1 = requests.get(\n",
    "    # call the entities endpoint\n",
    "    'https://api.signal-ai.com/entities',\n",
    "    params={\n",
    "        # Look for entities containing the token 'Environment'\n",
    "        'name':'Environment',\n",
    "        # Limit the search to organisations\n",
    "        'type':'organisation',\n",
    "        # 'from-cursor' is found under the'next-cursor' key in the previous response\n",
    "        'from-cursor': page_0.json().get('next-cursor')\n",
    "        \n",
    "    },\n",
    "    # include the access token in the header\n",
    "    headers={\n",
    "        \"Authorization\": f'Bearer {TEMP_ACCESS_TOKEN}',\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    ")\n",
    "\n",
    "page_1.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will frequently need to iterate over pages returned from the API, let's create a class called Paginate to manage this for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "def response_to_url(response) -> str:\n",
    "    \"\"\" get the url from a response \"\"\"\n",
    "    obj = urlparse(response.request.url)\n",
    "    return f\"{obj.scheme}://{obj.netloc}{obj.path}\"\n",
    "\n",
    "def response_to_params(response) -> dict:\n",
    "    \"\"\" get the params from a response \"\"\"\n",
    "    obj = urlparse(response.request.url)\n",
    "    return parse_qs(obj.query)\n",
    "\n",
    "def response_to_body(response) -> dict:\n",
    "    body = response.request.body\n",
    "    return json.loads(body.decode()) if body is not None else {}\n",
    "\n",
    "\n",
    "class Paginate:\n",
    "    \"\"\" \n",
    "    A class to iterate over API requestes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, response):\n",
    "        self.response = response\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def _get(self, response):\n",
    "        \"\"\" get the next get request from the previous one \"\"\"\n",
    "        nxt = response.json().get('next-cursor', None)\n",
    "        # the absence of next-cursor signifies we have reached the final page\n",
    "        if not nxt:\n",
    "            return None\n",
    "        params = response_to_params(response)\n",
    "        params['from-cursor'] = nxt\n",
    "        return requests.request(\n",
    "                'GET',\n",
    "                response_to_url(response),\n",
    "                headers=response.request.headers,\n",
    "                params=params,\n",
    "        )\n",
    "    \n",
    "    def _post(self, response):\n",
    "        nxt = response.json().get('next-cursor', None)\n",
    "        if not nxt:\n",
    "            return None\n",
    "        body = response_to_body(response)\n",
    "        body['from-cursor'] = nxt\n",
    "        return requests.request(\n",
    "                'POST',\n",
    "                response_to_url(response),\n",
    "                headers=response.request.headers,\n",
    "                json=body,\n",
    "        )\n",
    "        \n",
    "    # retry requests with an exponentially increasing wait time upto 10 times\n",
    "    @backoff.on_exception(backoff.expo, RateLimitError, max_value=10)\n",
    "    def __next__(self):\n",
    "        \"\"\" get the next response from the previous one \"\"\"\n",
    "        response = self.response\n",
    "\n",
    "        # Check if we have reached the final page\n",
    "        if not response:\n",
    "            raise StopIteration()\n",
    "        \n",
    "        # cehck if we hit the rate limit\n",
    "        if response.status_code == 429: \n",
    "            raise RateLimitError\n",
    "\n",
    "        # check if the response is valid\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        \n",
    "        method = response.request.method\n",
    "        if method == 'GET':\n",
    "            self.response = self._get(response)\n",
    "        elif method == 'POST':\n",
    "            self.response = self._post(response)\n",
    "        else:\n",
    "            raise ValueError(f'{method} method not supported')\n",
    "\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily loop over pages in a pythonic way. \n",
    "Below we get all the the results for our search by iterating over all the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "response = request('GET', 'entities', {'name': 'Environment'})\n",
    "for page in Paginate(response):\n",
    "    results.extend(page.json()['entities'])\n",
    "print(f'{len(results)} results found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Discovery Endpoints\n",
    "\n",
    "We now have all we need to explore all of the API endpoints in detail.\n",
    "We'll start with the discovery endpoints since they are the simplest, and illustrate their usage using code.\n",
    "Use these endpoints to discover which entities and topics are in the system:\n",
    "we will use the IDs returned in our subsequent searches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Entities are named people, organisations, locations, substances, diseases and products\n",
    "which all have a unique identifier within the Signal AI API.\n",
    "\"\"\"\n",
    "\n",
    "def get_entity(uuid):\n",
    "    \"\"\" Get a specific entity by its unique identifier \"\"\"\n",
    "    return request('GET', f'entities/{uuid}').json().get('entity')\n",
    "\n",
    "def search_entities(name: str = None, typ: str = None, size: int = None):\n",
    "    \"\"\"\n",
    "    Search for entities using any combination of name and type\n",
    "\n",
    "    name: Any entity whose name contains this search term will match\n",
    "    type: Enum: \"person\" \"organisation\" \"location\" \"substance\" \"disease\" \"product\"\n",
    "    size: number of entities per response (affects page size, not search results)\n",
    "    \"\"\"\n",
    "    response = request('GET', 'entities', {'name': name, 'type': typ, 'size': size})\n",
    "    results = []\n",
    "    for page in Paginate(response):\n",
    "        results.extend(page.json().get('entities'))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can search for entities with any combination of `name` and `type` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_entities(name=\"Conservation\", typ=\"organisation\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a specific entity by id\n",
    "get_entity('6a29ecbc-a8e8-3a73-b172-5efe4901b8e4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics and Sources have very similar interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Signal AI experts have trained over 300 topics (or themes), \n",
    "from Health to Blockchain to provide clients an easy way \n",
    "to track emerging trends relevant to their businesses. \"\"\"\n",
    "\n",
    "def get_topic(uuid):\n",
    "    \"\"\" Get a topic by id \"\"\"\n",
    "    return request('GET', f'topics/{uuid}').json().get('topic')\n",
    "\n",
    "def search_topics(name: str = None, size=10, private=False):\n",
    "    \"\"\"\n",
    "    Search A.I. trained topics by name\n",
    "\n",
    "    name: Any topic whose name contains this search term will match\n",
    "    size: number of entities per request (effects performance, not search results)\n",
    "    private: Only return topics which are private to your organisation\n",
    "    \"\"\"\n",
    "    response = request('GET', 'topics', {'name': name, 'size': size, 'private': str(private).lower()})\n",
    "    results = []\n",
    "    for page in Paginate(response):\n",
    "        results.extend(page.json().get('topics'))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_topics(name='Energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sources(uuid):\n",
    "    \"\"\" Get a publication source by id \"\"\"\n",
    "    return self.request('GET', f'sources/{uuid}').json().get('source')\n",
    "\n",
    "def search_sources(\n",
    "    name: str = None, size: int = None, country: str = None,\n",
    "    region: str = None, subregion: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Search publication sources\n",
    "\n",
    "    name: Any publication whose name contains this search term will match\n",
    "    size: number of entities per request (effects performance, not search results)\n",
    "    country: Country name\n",
    "    region: Region name\n",
    "    subregion: Subregion name\n",
    "    \"\"\"\n",
    "    response = request(\n",
    "        'GET',\n",
    "        'sources',\n",
    "        {\n",
    "            'name': name, 'size': size, 'country': country,\n",
    "            'region': region, 'subregion': subregion\n",
    "        }\n",
    "    )\n",
    "    results = []\n",
    "    for page in Paginate(response):\n",
    "        results.extend(page.json().get('sources'))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sources(name='Guardian', country='United Kingdom')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Endpoint\n",
    "\n",
    "The search endpoint allows the user to search for documents.\n",
    "Each document is tagged with metadata such as date of publication, language and all of the topics, sources and entities mentioned in the document.\n",
    "In addition the sentiment, saliency and sentiment of each mention is available.\n",
    "This makes the search endpoint a good way to explore when different tags are mentioned as well as how they occur with other topics and entities.\n",
    "\n",
    "The search endpoint is very powerful and offers a lot of freedom.\n",
    "To see all the possibilities it's best to look at the API docs.\n",
    "Here we will explore some examples to get a flavour for what is possible.\n",
    "The query needs to be provided as a JSON object and represents a filter for which documents are relevant.\n",
    "Keep in mind that very broad queries might take a long time to return all the results.\n",
    "\n",
    "Make sure you look at the documentation if you want to take full advantage of this endpoint:\n",
    "\n",
    "https://api.signal-ai.com/docs#tag/Content-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query):\n",
    "    documents = []\n",
    "    response = request('POST', 'search', json=query)\n",
    "    total = response.json().get('stats').get('total')\n",
    "    if total == 0:\n",
    "        return []\n",
    "    n_pages = total/len(response.json().get('documents'))\n",
    "    # Use a progress bar, big queries may take some time\n",
    "    for page in tqdm(Paginate(response), total=math.ceil(n_pages)):\n",
    "        documents.extend(page.json()['documents'])\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example query and the results\n",
    "\n",
    "## Example 1: Searching for stories about the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_topics(name='environment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "todays = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "three_days_ago = (datetime.datetime.today() - datetime.timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "a_month_ago = (datetime.datetime.today() - datetime.timedelta(days=30)).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = {\n",
    "    'where': {\n",
    "        # documents from the last 3 days\n",
    "        \"published-at\": {\"gt\": three_days_ago, \"lte\": todays},\n",
    "        'topics': {\n",
    "            'id': {\n",
    "                # id for the environment topic found using the dicovery endpoints\n",
    "                'eq': '7a162a73-0062-4772-9dc0-252dd862dad0'\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    'size': 500\n",
    "}\n",
    "documents = search_documents(query)\n",
    "print(f'{len(documents)} documents found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Search for stories about Greenpeace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_entities(name='Greenpeace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'where': {\n",
    "        \"published-at\": {\"gt\": three_days_ago , \"lt\": todays},\n",
    "        'topics': {\n",
    "            'id': {\n",
    "                'eq': '7a162a73-0062-4772-9dc0-252dd862dad0'\n",
    "            },\n",
    "        },\n",
    "        'entities': {\n",
    "            'id': {\n",
    "                # id for greenpeace\n",
    "                'eq': 'f09d0747-d36d-400e-8aca-a1b5d51c65f7'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'size': 500\n",
    "}\n",
    "documents = search_documents(query)\n",
    "print(f'{len(documents)} documents found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Sentiment about BP when Greta Thunberg is mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = {\n",
    "    'where': {\n",
    "        # search over the last month\n",
    "        \"published-at\": {\"gt\": a_month_ago, \"lte\": todays},\n",
    "        'topics': {\n",
    "            'id': {\n",
    "                'eq': '7a162a73-0062-4772-9dc0-252dd862dad0'\n",
    "            },\n",
    "        },\n",
    "        # both BP and Greta Thunberg\n",
    "        'entities': {\n",
    "            'id': {\n",
    "                'all': [\n",
    "                    '52e28982-5bd9-40d4-ab8f-7cba471f598c',\n",
    "                    '2bf240bf-bbc2-4416-910a-608a3fdd967d'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'size': 500\n",
    "}\n",
    "documents = search_documents(query)\n",
    "print(f'{len(documents)} documents found')\n",
    "\n",
    "entities_df = pd.DataFrame.from_records([e for d in documents for e in d.get('entities', [])]).set_index('id')\n",
    "entities_df[\n",
    "    # Filter for salient mentions\n",
    "    (entities_df['salient']==True)\n",
    "].loc['52e28982-5bd9-40d4-ab8f-7cba471f598c'].sentiment.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Sentiment about BP when Mexico is mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_entities(name='Mexico', typ='location')[:3]\n",
    "\n",
    "query = {\n",
    "    'where': {\n",
    "        # search over a 1 year period\n",
    "        \"published-at\": {\"gt\": a_month_ago, \"lte\": todays},\n",
    "        'topics': {\n",
    "            'id': {\n",
    "                'eq': '7a162a73-0062-4772-9dc0-252dd862dad0'\n",
    "            },\n",
    "        },\n",
    "        # both BP and Mexico\n",
    "        'entities': {\n",
    "            'id': {\n",
    "                # to look for either entity use the key 'or'\n",
    "                'all': [\n",
    "                    '52e28982-5bd9-40d4-ab8f-7cba471f598c',\n",
    "                    '995444c6-eae3-400c-9457-0393b51efe0e'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'size': 500\n",
    "}\n",
    "documents = search_documents(query)\n",
    "print(f'{len(documents)} documents found')\n",
    "\n",
    "entities_df = pd.DataFrame.from_records([e for d in documents for e in d.get('entities', [])\n",
    "]).set_index('id')\n",
    "entities_df = pd.DataFrame.from_records([e for d in documents for e in d.get('entities', [])]).set_index('id')\n",
    "entities_df[\n",
    "    # Filter for salient mentions\n",
    "    (entities_df['salient']==True)\n",
    "].loc['52e28982-5bd9-40d4-ab8f-7cba471f598c'].sentiment.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: People and Organisations mentioned alongside Greta Thunberg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'where': {\n",
    "        \"published-at\": {\"gt\": three_days_ago, \"lte\": todays},\n",
    "        'topics': {\n",
    "            'id': {\n",
    "                'eq': '7a162a73-0062-4772-9dc0-252dd862dad0'\n",
    "            },\n",
    "        },\n",
    "        'entities': {\n",
    "            'id': {\n",
    "                'eq': '2bf240bf-bbc2-4416-910a-608a3fdd967d'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'size': 500\n",
    "}\n",
    "documents = search_documents(query)\n",
    "print(f'{len(documents)} documents found')\n",
    "entities_df = pd.DataFrame.from_records([e for d in documents for e in d.get('entities', [])])\n",
    "entities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df[entities_df['type'] == 'person']['name'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df[entities_df['type'] == 'organisation']['name'].value_counts().head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
